# -*- coding: utf-8 -*-
"""Simulation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VZTx0jickZGOWajWUpuqhFFNOPiPsFa1
"""

import tensorflow as tf
from transformers import AutoTokenizer
import numpy as np

# Load the saved BiLSTM model
model = tf.keras.models.load_model("fake_news_bilstm_model.keras")

# Load the same tokenizer used during training
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Define label mapping (for binary classification: 0 = Fake, 1 = Real)
label_map = {0: "FAKE", 1: "REAL"}

def preprocess_text(text, max_len=128):
    tokens = tokenizer(
        text,
        padding='max_length',
        truncation=True,
        max_length=max_len,
        return_tensors='np'
    )
    return tokens["input_ids"]

# CLI loop to input news and predict
while True:
    print("\nEnter a news article (title + content) or type 'exit' to quit:")
    user_input = input("ðŸ“° News Text: ")

    if user_input.lower() == "exit":
        print("Exiting...")
        break

    input_ids = preprocess_text(user_input)
    predictions = model.predict(input_ids)
    predicted_label = np.argmax(predictions, axis=1)[0]
    confidence = np.max(predictions)

    print(f"\nðŸ§  Prediction: {label_map[predicted_label]} (Confidence: {confidence:.2f})")